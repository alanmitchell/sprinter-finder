{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscrape Sprinter Camper Vans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from datetime import datetime\n",
    "import re\n",
    "from random import randint #avoid throttling by not sending too many requests one after the other\n",
    "from warnings import warn\n",
    "from time import time\n",
    "from IPython.core.display import clear_output\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# import get to call a get request on the site\n",
    "from requests import get\n",
    "from jinja2 import Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.ResultSet'>\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "#get the first page of the east bay housing prices\n",
    "response = get('https://portland.craigslist.org/search/sss?max_price=100000&query=sprinter+4wd&min_price=40000')\n",
    "html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "#get the macro-container for the housing posts\n",
    "posts = html_soup.find_all('li', class_= 'result-row')\n",
    "print(type(posts)) #to double check that I got a ResultSet\n",
    "print(len(posts)) #to double check I got 120 (elements/page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab the first post\n",
    "post_one = posts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$42995'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grab the price of the first post\n",
    "post_one_price = post_one.a.text\n",
    "post_one_price.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-01-28 07:10'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grab the time of the post in datetime format to save on cleaning efforts\n",
    "post_one_time = post_one.find('time', class_= 'result-date')\n",
    "post_one_datetime = post_one_time['datetime']\n",
    "post_one_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2016 Porsche Cayenne All Wheel Drive S E-Hybrid AWD 26k Mi Vented Seats Pano Roo'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#title is a and that class, link is grabbing the href attribute of that variable\n",
    "post_one_title = post_one.find('a', class_='result-title hdrlnk')\n",
    "post_one_link = post_one_title['href']\n",
    "\n",
    "#easy to grab the post title by taking the text element of the title variable\n",
    "post_one_title_text = post_one_title.text\n",
    "post_one_title_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grabs the whole segment of housing details. We will need missing value handling in the loop as this kind of detail is not common in posts\n",
    "#the text can be split, and we can use indexing to grab the elements we want. number of bedrooms is the first element.\n",
    "#sqft is the third element\n",
    "\n",
    "#post_one_num_bedrooms = post_one.find('span', class_ = 'housing').text.split()[0]\n",
    "\n",
    "#post_one_sqft = post_one.find('span', class_ = 'housing').text.split()[2][:-3] #cleans the ft2 at the end\n",
    "\n",
    "#the neighborhood is grabbed by finding the span class 'result-hood' and pulling the text element from that\n",
    "#post_one_hood = posts[0].find('span', class_='result-hood').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................\n",
      "Scrape complete!\n",
      "Downloading Posts...\n",
      "..................................."
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "### min_price=40000&max_price=100000&query=sprinter+4x4+camper\n",
       "\n",
       "[$86000, 5 days ago, 4x4 sprinter crew camper conversion van](https://portland.craigslist.org/wsc/for/d/tacoma-4x4-sprinter-crew-camper/7065037633.html)\n",
       "\n",
       "[$86000, 5 days ago, 2019 Mercedes Sprinter 4x4 camper conversion van](https://seattle.craigslist.org/tac/for/d/tacoma-2019-mercedes-sprinter-4x4/7064917221.html)\n",
       "\n",
       "[$86000, 6 days ago, 2019 Mercedes Sprinter 4x4 Crew Camper van](https://seattle.craigslist.org/tac/for/d/tacoma-2019-mercedes-sprinter-4x4-crew/7064275055.html)\n",
       "\n",
       "[$84000, 7 days ago, 2017 Mercedes Benz Sprinter 2500 4X4  **Price Reduced **](https://bozeman.craigslist.org/ctd/d/belgrade-2017-mercedes-benz-sprinter-x4/7063350440.html)\n",
       "\n",
       "[$61000, 9 days ago, Brand new 4x4 Sprinter](https://portland.craigslist.org/mlt/rvs/d/sherwood-brand-new-4x4-sprinter/7062408953.html)\n",
       "\n",
       "[$42000, 10 days ago, 2016 4x4 Mercedes Sprinter 170 Crew](https://sfbay.craigslist.org/sfc/cto/d/san-francisco-x4-mercedes-sprinter-170/7061971670.html)\n",
       "\n",
       "[$45000, 16 days ago, 1989 VW Vanagon Syncro Westfalia - CARB legal 1.8t - 200hp](https://losangeles.craigslist.org/lgb/cto/d/la-mirada-1989-vw-vanagon-syncro/7058237079.html)\n",
       "\n",
       "[$90000, 21 days ago, 2016 Sprinter 4x4 Camper Van](https://ventura.craigslist.org/cto/d/ventura-2016-sprinter-4x4-camper-van/7055020507.html)\n",
       "\n",
       "\n",
       "### min_price=40000&max_price=100000&query=sprinter+4x4+conversion\n",
       "\n",
       "[$84500, 3 days ago, 2018 Mercedes-Benz Sprinter 2500 Passenger High Roof w/144 WB Van 3D](https://boise.craigslist.org/ctd/d/boise-2018-mercedes-benz-sprinter-2500/7065874797.html)\n",
       "\n",
       "[$84500, 3 days ago, 2018 Mercedes-Benz Sprinter 2500 Passenger High Roof w/144 WB Van 3D](https://boise.craigslist.org/ctd/d/boise-2018-mercedes-benz-sprinter-2500/7065873655.html)\n",
       "\n",
       "[$69999, 3 days ago, 2019 Mercedes-Benz Sprinter 2500 Cargo Standard Roof w/144 WB Van 3D](https://boise.craigslist.org/ctd/d/boise-2019-mercedes-benz-sprinter-2500/7065872653.html)\n",
       "\n",
       "[$67500, 3 days ago, 2019 Freightliner Sprinter 2500 Cargo High Roof w/170 WB Van 3D](https://boise.craigslist.org/ctd/d/boise-2019-freightliner-sprinter-2500/7065872274.html)\n",
       "\n",
       "[$69998, 3 days ago, 2016 Mercedes-Benz Sprinter 2500 Crew High Roof w/144 WB Van 3D](https://boise.craigslist.org/ctd/d/boise-2016-mercedes-benz-sprinter-2500/7065875623.html)\n",
       "\n",
       "[$69999, 6 days ago, 2019 Mercedes-Benz Sprinter 2500 Cargo High Roof w/170 WB Van 3D](https://boise.craigslist.org/ctd/d/boise-2019-mercedes-benz-sprinter-2500/7064172509.html)\n",
       "\n",
       "[$84500, 6 days ago, 2018 Mercedes-Benz Sprinter 2500 Passenger High Roof w/144 WB Van 3D](https://boise.craigslist.org/ctd/d/boise-2018-mercedes-benz-sprinter-2500/7064177849.html)\n",
       "\n",
       "[$84500, 6 days ago, 2018 Mercedes-Benz Sprinter 2500 Passenger High Roof w/144 WB Van 3D](https://boise.craigslist.org/ctd/d/boise-2018-mercedes-benz-sprinter-2500/7064176802.html)\n",
       "\n",
       "[$69998, 6 days ago, 2016 Mercedes-Benz Sprinter 2500 Crew High Roof w/144 WB Van 3D](https://boise.craigslist.org/ctd/d/boise-2016-mercedes-benz-sprinter-2500/7064174801.html)\n",
       "\n",
       "[$67500, 6 days ago, 2019 Freightliner Sprinter 2500 Cargo High Roof w/170 WB Van 3D](https://boise.craigslist.org/ctd/d/boise-2019-freightliner-sprinter-2500/7064175223.html)\n",
       "\n",
       "[$69998, 9 days ago, 2019 Freightliner Sprinter 2500 Cargo High Roof w/170 WB Van 3D](https://boise.craigslist.org/ctd/d/boise-2019-freightliner-sprinter-2500/7062114231.html)\n",
       "\n",
       "[$69998, 9 days ago, 2016 Mercedes-Benz Sprinter 2500 Crew High Roof w/144 WB Van 3D](https://boise.craigslist.org/ctd/d/boise-2016-mercedes-benz-sprinter-2500/7062114512.html)\n",
       "\n",
       "[$61000, 9 days ago, Brand New 2019 Sprinter 4x4](https://sfbay.craigslist.org/sby/rvs/d/san-jose-brand-new-2019-sprinter-4x4/7062406165.html)\n",
       "\n",
       "[$84500, 9 days ago, 2018 Mercedes-Benz Sprinter 2500 Passenger High Roof w/144 WB Van 3D](https://boise.craigslist.org/ctd/d/boise-2018-mercedes-benz-sprinter-2500/7062114980.html)\n",
       "\n",
       "[$69999, 9 days ago, 2019 Mercedes-Benz Sprinter 2500 Cargo High Roof w/170 WB Van 3D](https://boise.craigslist.org/ctd/d/boise-2019-mercedes-benz-sprinter-2500/7062118370.html)\n",
       "\n",
       "[$84500, 9 days ago, 2018 Mercedes-Benz Sprinter 2500 Passenger High Roof w/144 WB Van 3D](https://boise.craigslist.org/ctd/d/boise-2018-mercedes-benz-sprinter-2500/7062117664.html)\n",
       "\n",
       "[$58500, 16 days ago, Sprinter 2018 4x4 Passenger 144](https://bozeman.craigslist.org/cto/d/bozeman-sprinter-x4-passenger-144/7058034388.html)\n",
       "\n",
       "[$69999, 18 days ago, 2019 Mercedes-Benz Sprinter 2500 Cargo High Roof w/170 WB Van 3D](https://boise.craigslist.org/ctd/d/boise-2019-mercedes-benz-sprinter-2500/7056668133.html)\n",
       "\n",
       "[$82500, 20 days ago, 2018 Mercedes-Benz Sprinter 2500 Passenger High Roof w/144 WB Van 3D](https://boise.craigslist.org/ctd/d/boise-2018-mercedes-benz-sprinter-2500/7055543154.html)\n",
       "\n",
       "[$79999, 20 days ago, 2018 Mercedes-Benz Sprinter 2500 Passenger High Roof w/144 WB Van 3D](https://boise.craigslist.org/ctd/d/boise-2018-mercedes-benz-sprinter-2500/7055537077.html)\n",
       "\n",
       "[$74500, 20 days ago, 2019 Mercedes-Benz Sprinter 2500 Cargo Standard Roof w/144 WB Van 3D](https://boise.craigslist.org/ctd/d/boise-2019-mercedes-benz-sprinter-2500/7055537254.html)\n",
       "\n",
       "[$69998, 20 days ago, 2016 Mercedes-Benz Sprinter 2500 Crew High Roof w/144 WB Van 3D](https://boise.craigslist.org/ctd/d/boise-2016-mercedes-benz-sprinter-2500/7055537396.html)\n",
       "\n",
       "[$69998, 20 days ago, 2019 Freightliner Sprinter 2500 Cargo High Roof w/170 WB Van 3D](https://boise.craigslist.org/ctd/d/boise-2019-freightliner-sprinter-2500/7055535194.html)\n",
       "\n",
       "[$89900, 23 days ago, 2016 4x4 Fully-Loaded 170\" Sprinter Van: Seat 4/Sleep 4 Conversion](https://denver.craigslist.org/cto/d/golden-x4-fully-loaded-170-sprinter-van/7053600219.html)\n",
       "\n",
       "[$79999, 25 days ago, 2018 Mercedes-Benz Sprinter 2500 Passenger High Roof w/144 WB Van 3D](https://boise.craigslist.org/ctd/d/boise-2018-mercedes-benz-sprinter-2500/7052207080.html)\n",
       "\n",
       "[$82500, 25 days ago, 2018 Mercedes-Benz Sprinter 2500 Passenger High Roof w/144 WB Van 3D](https://boise.craigslist.org/ctd/d/boise-2018-mercedes-benz-sprinter-2500/7052205181.html)\n",
       "\n",
       "[$89000, 27 days ago, 2017 Sprinter Van 4x4 Conversion Build](https://phoenix.craigslist.org/nph/cto/d/flagstaff-2017-sprinter-van-4x4/7050776154.html)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build out the loop\n",
    "#find the total number of posts to find the limit of the pagination\n",
    "#results_num = html_soup.find('div', class_= 'search-legend')\n",
    "#results_total = int(results_num.find('span', class_='totalcount').text) #pulled the total count of posts as the upper bound of the pages array\n",
    "\n",
    "#each page has 119 posts so each new page is defined as follows: s=120, s=240, s=360, and so on. So we need to step in size 120 in the np.arange function\n",
    "#pages = np.arange(0, results_total+1, 120)\n",
    "\n",
    "iterations = 0\n",
    "\n",
    "days_ago = []\n",
    "post_title_texts = []\n",
    "post_links = []\n",
    "post_prices = []\n",
    "search_ixs = []\n",
    "post_ixs = [] \n",
    "\n",
    "# Craiglist cities to search\n",
    "cities = (\n",
    "    'anchorage',\n",
    "    'fairbanks',\n",
    "    'portland',\n",
    "    'seattle',\n",
    "    'denver',\n",
    "    'madison',\n",
    "    'boulder',\n",
    "    'bozeman',\n",
    "    'boise',\n",
    "    'sfbay',\n",
    "    'phoenix',\n",
    "    'saltlakecity',\n",
    "    'albuquerque',\n",
    "    'minneapolis',\n",
    "    'wyoming',\n",
    "    'losangeles',\n",
    ")\n",
    "\n",
    "# Search strings\n",
    "searches = (\n",
    "    'min_price=40000&max_price=100000&query=sprinter+4x4+camper',\n",
    "    'min_price=40000&max_price=100000&query=sprinter+4x4+conversion',\n",
    "    #'min_price=40000&max_price=100000&query=sprinter+4wd+camper',\n",
    "    #'query=electric+bicycle&min_price=700&max_price=2000',\n",
    ")\n",
    "post_ix = 0    # counts the posts downloaded\n",
    "for city in cities:\n",
    "        \n",
    "    for search_ix, search in enumerate(searches):\n",
    "\n",
    "        #get request\n",
    "        response = get(f\"https://{city}.craigslist.org/search/sss?{search}&\" \n",
    "                       + \"s=0\" #the parameter for defining the page number \n",
    "                      )\n",
    "        sleep(randint(1,5))\n",
    "\n",
    "        #throw warning for status codes that are not 200\n",
    "        if response.status_code != 200:\n",
    "            warn('Request: {}; Status code: {}'.format(requests, response.status_code))\n",
    "\n",
    "        #define the html text\n",
    "        page_html = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        #define the posts\n",
    "        posts = page_html.find_all('li', class_= 'result-row')\n",
    "\n",
    "        #extract data item-wise\n",
    "        for post in posts:\n",
    "\n",
    "            # posting date\n",
    "            # grab the datetime element 0 for date and 1 for time\n",
    "            post_datetime = post.find('time', class_= 'result-date')['datetime']\n",
    "            dt = datetime.strptime(post_datetime, '%Y-%m-%d %H:%M')\n",
    "            ago = (datetime.now() - dt).days\n",
    "\n",
    "            # title text\n",
    "            post_title = post.find('a', class_='result-title hdrlnk')\n",
    "            post_title_text = post_title.text\n",
    "\n",
    "            # Filter out some posts\n",
    "            title_lower = post_title_text.lower()\n",
    "\n",
    "            excl_words = (\n",
    "                'promaster',\n",
    "                'ford',\n",
    "                'porsche',\n",
    "                'dodge',\n",
    "                'isuzu',\n",
    "                'roadster',\n",
    "                'toyota',\n",
    "                'jeep',\n",
    "            )\n",
    "            done = False\n",
    "            for wd in excl_words:\n",
    "                if wd in title_lower:\n",
    "                    done = True\n",
    "            if done:\n",
    "                continue\n",
    "\n",
    "            # post link\n",
    "            post_link = post_title['href']\n",
    "\n",
    "            # removes the \\n whitespace from each side, removes the currency symbol, and turns it into an int\n",
    "            try:\n",
    "                post_price = int(post.a.text.strip().replace(\"$\", \"\")) \n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "            \n",
    "            days_ago.append(ago)\n",
    "            post_title_texts.append(post_title_text)\n",
    "            post_links.append(post_link)\n",
    "            post_prices.append(post_price)\n",
    "            search_ixs.append(search_ix)\n",
    "            post_ixs.append(post_ix)\n",
    "            post_ix += 1\n",
    "\n",
    "        iterations += 1\n",
    "        print('.', end='')\n",
    "\n",
    "print(\"\\nScrape complete!\")\n",
    "\n",
    "vans = pd.DataFrame({'days_ago': days_ago,\n",
    "                       'title': post_title_texts,\n",
    "                        'URL': post_links,\n",
    "                       'price': post_prices,\n",
    "                       'search_ix': search_ixs,\n",
    "                       'post_ix': post_ixs,\n",
    "                    })\n",
    "\n",
    "# first things first, drop duplicate URLs because people are spammy on Craigslist. \n",
    "vans = vans.drop_duplicates(subset='URL')\n",
    "\n",
    "# Download the detailed post page for the remaining items\n",
    "print('Downloading Posts...')\n",
    "local_urls = []\n",
    "for row_ix, row in vans.iterrows():\n",
    "    post_html = get(row.URL).text\n",
    "    post_lines = post_html.splitlines()\n",
    "    for ix, line in enumerate(post_lines):\n",
    "        if 'class=\"tryapp\"' in line:\n",
    "            start_ix = ix\n",
    "            break\n",
    "    for ix, line in enumerate(post_lines):\n",
    "        if 'class=\"postingtitle\"' in line:\n",
    "            end_ix = ix\n",
    "            break\n",
    "    post_lines = post_lines[:start_ix] + post_lines[end_ix:]\n",
    "    local_url = f'posts/{row_ix}.html'\n",
    "    open(local_url, 'w').write('\\n'.join(post_lines))\n",
    "    local_urls.append(local_url)\n",
    "    print('.', end='')\n",
    "    sleep(randint(1,5))\n",
    "vans['local_url'] = local_urls\n",
    "\n",
    "result = ''\n",
    "for ix, srch in enumerate(searches):\n",
    "    result += f'\\n### {srch}\\n\\n'\n",
    "    for _, row in vans.sort_values(by=['days_ago']).query(f'search_ix == {ix}').iterrows():\n",
    "        result += f'[${row.price:.0f}, {row.days_ago} days ago, {row.title}]({row.URL})\\n\\n'\n",
    "Markdown(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10553"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for ix, srch in enumerate(searches):\n",
    "    srch = srch.replace('&', '<br>').replace('+', ' ')\n",
    "    items = []\n",
    "    for _, row in vans.query(f'search_ix == {ix}').sort_values(by=['days_ago']).iterrows():\n",
    "        items.append((f'${row.price:.0f}, {row.days_ago} days ago, {row.title}', row.URL, row.local_url))\n",
    "    results.append((srch, items))\n",
    "t = Template(open('results_tmpl.html',).read())\n",
    "open('results.html', 'w').write(t.render(results=results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
